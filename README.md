# nanoLLaMA with stories

This is a minimal implementation of [Andrej Karpathy](https://karpathy.ai/)'s [llama2.c](https://github.com/karpathy/llama2.c) project.

To reduce the parameters to be passed to the executable to zero I inserted the stories260k model data and the tokenizer data into the header file. That's all.

gcc -O3 -o stories stories.c -lm

./stories

Lila was a secret. She thought, "It's okay. How be win!"
Lily thought about it. She wanted a new friend to try the sign. She tried to put back on the basket together. She thought about it. She asked, "What is that if we don't give up, Tim, you have to brush the air."
The bald tand was over the big basket. It had too clumsy. It went to the tall room and smiled. Lily wanted to catch the basketball. She started to run and Ben wanted to be your toy claying, but he could not stay so hard. He went to his.
